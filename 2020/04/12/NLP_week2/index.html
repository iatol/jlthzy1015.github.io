<!DOCTYPE html><html lang="zh-CN"><!--
             -. .                                        
       _____   ',' ,                                    
     ,'     ,'   ', ',                                  
   ,'     ,'      |  |                                  
   \       \       |  |                                  
     \ /^\   \    ,' ,'                                  
           \   \ ,' ,'      L'Internationale,            
     / ~-.___\.-'  ,'            Sera le genre humain.   
   /   .______.- ~ \                                     
 /   /'          \   \                                   
 \./               \/'                                   
                                                         
--><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Jlthzy"><title>NLP_week2 · Jlthzy's Blog</title><meta name="description" content="1.总述Week2的实验有一定难度，开始调库了，个人感觉难点在于分析正确率。翻看老师的ppt，感觉回到了模式识别课程。说到模式识别，还是挺感谢fyc老师，给了我高分，嘿嘿！
2.实验内容1）使用任意分词方法编写算法实现汉语自动分词，我用的是HMM2）调用2种及以上分词工具进行分词，我用的是Jieba"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style-dark.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/valine.min.js"></script><meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><span class="donate-address">唯一指定邮箱：Jlthzy123@gmail.com</span><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">当我拥着光亮 ⭐ 环着希望</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">就是这样 </a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/abouts/index.html">关于</a></li><li><a href="/tags/index.html"></a></li><li><a href="/categories/index.html"></a></li><li><a href="/archives/index.html"></a></li><li class="soc"><a href="https://github.com/jlthzy1015" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a><a href="https://twitter.com/xxxxx" target="_blank" rel="noopener noreferrer"><i class="fa fa-twitter">&nbsp;</i></a><a href="https://www.instagram.com/xxxxx" target="_blank" rel="noopener noreferrer"><i class="fa fa-instagram">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2020&nbsp;<a target="_blank" href="https://leohu.me" rel="noopener noreferrer">Jlthzy</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><h1 class="post-title">NLP_week2</h1><p class="post-meta"><span class="date meta-item">发布于&nbsp;2020-04-12</span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/nlp/" title="nlp" class="a-tag">nlp</a><span>&nbsp;</span></span></p><p class="post-abstract"><h3 id="1-总述"><a href="#1-总述" class="headerlink" title="1.总述"></a>1.总述</h3><p>Week2的实验有一定难度，开始调库了，个人感觉难点在于分析正确率。翻看老师的ppt，感觉回到了模式识别课程。说到模式识别，还是挺感谢fyc老师，给了我高分，嘿嘿！</p>
<h3 id="2-实验内容"><a href="#2-实验内容" class="headerlink" title="2.实验内容"></a>2.实验内容</h3><p>1）使用任意分词方法编写算法实现汉语自动分词，我用的是<code>HMM</code><br>2）调用2种及以上分词工具进行分词，我用的是<code>Jieba</code>以及<code>SnowNLP</code>。<br>3）用两种方法，给出至少50个句子的分词结果（以附件形式）.<br>4)分别计算出两种分词结果的正确率，并给出计算依据。</p>
<h3 id="3-Code"><a href="#3-Code" class="headerlink" title="3.Code"></a>3.Code</h3><h4 id="3-1基于HMM的分词程序实现"><a href="#3-1基于HMM的分词程序实现" class="headerlink" title="3.1基于HMM的分词程序实现"></a>3.1基于HMM的分词程序实现</h4><p><a href="https://jlthzy.cc/archives/60/" target="_blank" rel="noopener" title="点我前往">点我前往</a></p>
<h4 id="3-2-调用jieba和snownlp实现分词并评价性能"><a href="#3-2-调用jieba和snownlp实现分词并评价性能" class="headerlink" title="3.2 调用jieba和snownlp实现分词并评价性能"></a>3.2 调用jieba和snownlp实现分词并评价性能</h4><h5 id="3-2-1-核心，Seg类-调用工具实现分词"><a href="#3-2-1-核心，Seg类-调用工具实现分词" class="headerlink" title="3.2.1 核心，Seg类:调用工具实现分词"></a>3.2.1 核心，Seg类:调用工具实现分词</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###...................................分词...................................###</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Seg</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">jieba</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="comment"># 结巴分词</span></span><br><span class="line">        jieba_result = list(jieba.cut(text))</span><br><span class="line">        <span class="keyword">return</span> jieba_result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">snownlp</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="comment"># SnowNLP</span></span><br><span class="line">        snownlp_result = snownlp.SnowNLP(text).words</span><br><span class="line">        <span class="keyword">return</span> snownlp_result</span><br></pre></td></tr></table></figure>
<h5 id="3-2-2-核心，Sta类：统计三类分词数目"><a href="#3-2-2-核心，Sta类：统计三类分词数目" class="headerlink" title="3.2.2 核心，Sta类：统计三类分词数目"></a>3.2.2 核心，Sta类：统计三类分词数目</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###...................................统计三类分词数目...................................###</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sta</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compare_line</span><span class="params">(self, reference, candidate)</span>:</span> <span class="comment"># reference 标注, candidate 为工具分词结果</span></span><br><span class="line">        ref_len = len(reference.replace(<span class="string">' '</span>, <span class="string">''</span>))</span><br><span class="line">        can_len = len(candidate.replace(<span class="string">' '</span>, <span class="string">''</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ref_words = reference.split()</span><br><span class="line">        can_words = candidate.split()</span><br><span class="line"></span><br><span class="line">        ref_words_len = len(ref_words)</span><br><span class="line">        can_words_len = len(can_words)</span><br><span class="line"></span><br><span class="line">        ref_index = []</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> ref_words:</span><br><span class="line">            word_index = [index]</span><br><span class="line">            index += len(word)</span><br><span class="line">            word_index.append(index)</span><br><span class="line">            ref_index.append(word_index)</span><br><span class="line"></span><br><span class="line">        can_index = []</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> can_words:</span><br><span class="line">            word_index = [index]</span><br><span class="line">            index += len(word)</span><br><span class="line">            word_index.append(index)</span><br><span class="line">            can_index.append(word_index)</span><br><span class="line"></span><br><span class="line">        tmp = [val <span class="keyword">for</span> val <span class="keyword">in</span> ref_index <span class="keyword">if</span> val <span class="keyword">in</span> can_index]</span><br><span class="line">        acc_word_len = len(tmp)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ref_words_len, can_words_len, acc_word_len</span><br></pre></td></tr></table></figure>
<h5 id="3-3-3-说明"><a href="#3-3-3-说明" class="headerlink" title="3.3.3 说明"></a>3.3.3 说明</h5><p>有了上面三个函数，基本框架就有了，写个主函数结果就出来了。</p>
<h3 id="4-Result"><a href="#4-Result" class="headerlink" title="4.Result"></a>4.Result</h3><p><img src="https://s1.ax1x.com/2020/04/12/GLiC7T.png" alt="Result" title="Result"></p>
</p></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2020/04/16/Trojan_web/" title="Trojan Web控制面板"><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: Trojan Web控制面板</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2020/04/10/x%E5%85%89%E8%82%BA%E7%82%8E%E5%A4%9A%E5%88%86%E7%B1%BB/" title="x光肺炎多分类">下一篇: x光肺炎多分类&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div><a id="comments"></a><div id="valine-container"></div><script>(function(){
    if(typeof Valine !== 'undefined'){
        new Valine({
            el:'#valine-container',
            appId: '4BnPmxhNaSW5zalGBEpEWBkU-gzGzoHsz',
            appKey: 'J0kuzWw1GHsnqBOrvRjYGUjL',
            path: window.location.pathname
        })
    }
}())
</script></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2020&nbsp;<a target="_blank" href="https://leohu.me" rel="noopener noreferrer">Jlthzy</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.min.js"></script></body></html>